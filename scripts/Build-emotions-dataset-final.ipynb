{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions ML Data Generation \n",
    "\n",
    "This notebook is built with the purpose of creating a large corpus to train and test a machine learning emotions classifier for the `limbic` package. \n",
    "\n",
    "\n",
    "## General Idea\n",
    "\n",
    "Given that currently the `limbic` package supports a very deterministic dictionary-based emotions classification, the idea is the following: \n",
    "1. Fetch a large corpus of texts. These texts need to have a wide range of emotions depicted inside. It's impossible to manually review for a reasonably distributed set of emotions in this corpus, so as a strong assumption I'll be picking as many books from different genres as I can. The hypothesis is that with a large enough set of large documents, the classifier will be able to pick the patterns on which emotions \n",
    "2. Pre-process such texts in order to isolate as many sentences as possible and run the current emotions classifier on each sentence. \n",
    "3. Aggregate such results to create a multi-category dataset where each sentence will be associated to many categories, and each category will have a strength as determined by the dictionary-based emotions classifier in `limbic`.\n",
    "4. Train a model using such dataset and then check the performance.\n",
    "\n",
    "For this, I picked a few books from https://www.smashwords.com/ that were free and their `txt` version was already available. This is just to get started, but this collection of cheesy fiction books from different genres which seem to be quite heavy on emotions so it might be a good sample (added a few non-fiction factual books to balance out too many emotions for the classifier). Also, I went throught the classic Guthemberg project and picked ~90 books from the top list https://www.gutenberg.org/browse/scores/top . The model will be built in TensorFlow using a bi-directional recurrent neural network for multi-label classification, and tested in a separate notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = {}  # This variable will keep track of all parameters used in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "total: 96 files.\n",
      "total paragraphs: 111006\n",
      "total lines: 432053\n",
      "total unique words ~ 252216\n",
      "max freq: ('the', 373777)\n",
      "freq 50k: ('malicious,', 5)\n",
      "freq 100k: ('Hollander', 2)\n",
      "freq 200k: ('across--till', 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Iterable\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "from limbic.emotion.models.tf_limbic_model import utils\n",
    "\n",
    "\n",
    "books_path = '../data/books/'  # books are included in this repository as a compressed file books.tar.gz \n",
    "files = [os.path.join(books_path, filename) for filename in os.listdir(books_path) if filename.endswith(\".txt\")]\n",
    "training_metadata['corpus_files'] = files\n",
    "training_metadata['corpus_total_files'] = len(files)\n",
    "print(f'--\\ntotal: {len(files)} files.')\n",
    "\n",
    "paragraphs = []\n",
    "for _file in files:\n",
    "    with open(_file, 'r') as f:\n",
    "        paragraphs += utils.load_book(f.readlines())\n",
    "training_metadata['corpus_total_paragraphs'] = len(paragraphs)\n",
    "print(f'total paragraphs: {len(paragraphs)}')\n",
    "\n",
    "# split all paragraph lines (using simple period and no question or exclamation marks)\n",
    "# TODO: An analysis on whether to use question marks or exclamation marks could be interesting ;)\n",
    "lines = []\n",
    "for p in paragraphs:\n",
    "    lines += [x.strip() for x in p.split('.') if x and len(x.split(' ')) > 1]  \n",
    "training_metadata['corpus_total_lines'] = len(lines)\n",
    "print(f'total lines: {len(lines)}')\n",
    "\n",
    "unique_words = Counter()\n",
    "for l in lines:\n",
    "    unique_words.update(l.split(' '))\n",
    "print(f'total unique words ~ {len(unique_words.keys())}')\n",
    "\n",
    "sorted_words = sorted(unique_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f'max freq: {sorted_words[0]}')\n",
    "print(f'freq 50k: {sorted_words[50000]}')\n",
    "print(f'freq 100k: {sorted_words[100000]}')\n",
    "print(f'freq 200k: {sorted_words[200000]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing dataset\n",
    "\n",
    "In this section we'll go through processing the corpus and create the training and testing dataset. \n",
    "\n",
    "The idea will be to use `limbic` to approximate in a deterministic (but not perfect) way which is the emotion of a sentence, and use these emotions as labels. As we do have many emotions in a sentence, the idea would be to model the problem into a multi-label classification problem. In cases where there's more than one label, I'll keep the max emotion associated to that label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from limbic.emotion.models import LexiconLimbicModel\n",
    "from limbic.emotion.nrc_utils import load_nrc_lexicon\n",
    "\n",
    "EMOTIONS_DICTIONARY_FILE = '../data/lexicons/NRC-AffectIntensity-Lexicon.txt'\n",
    "EMOTIONS_TYPE = 'affect_intensity'\n",
    "training_metadata['lexicon_limbic_model_params'] = {\n",
    "    'dictionary_file': EMOTIONS_DICTIONARY_FILE,\n",
    "    'emotions_type': EMOTIONS_TYPE\n",
    "}\n",
    "\n",
    "lexicon = load_nrc_lexicon(EMOTIONS_DICTIONARY_FILE, EMOTIONS_TYPE)\n",
    "lb = LexiconLimbicModel(lexicon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169463fd4b414181833a7361f9dbb69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='getting emotions', style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "CORPUS_LINES_SAMPLE = 100  # Small number for now to speed up experiments\n",
    "training_metadata['corpus_lines_sample'] = CORPUS_LINES_SAMPLE\n",
    "\n",
    "# Get the emotions for all sentences so we can use them as target labels \n",
    "# Note that this step takes considerable time if the len(lines) is used as CORPUS_LINES_SAMPLE (~4hrs), so be patient. \n",
    "sentence_emotions = {l: lb.get_sentence_emotions(l) \n",
    "                     for l in tqdm(random.sample(lines, CORPUS_LINES_SAMPLE), 'getting emotions')}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking how balanced is the data\n",
    "\n",
    "\n",
    "Running a counter over the different labels in the dataset, you can see that there's a small imbalance (biased towards \"joy\" emotions and the other emotions are mostly within a similar distribution. I'll keep the data like this unless I see there's some predicted biased towards the \"joy\" emotion (TODO). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bd178137eb4ebf95fc9460d53d7a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=95425), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95425"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from limbic.limbic_types import Emotion\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "\n",
    "# Here I'm cheating a little bit. I used 100 in the step above as example, but I'm loading data computed with 100000\n",
    "# Loading pre-computed version of sentence -> emotions as it takes a long time to compute for large datasets. \n",
    "\n",
    "sentence_emotions = {}\n",
    "with open('sentence_emotions.jsons', 'r') as se_file:\n",
    "    for line in tqdm(se_file.readlines()):\n",
    "        _d = json.loads(line.strip())\n",
    "        _emotions = [Emotion(term=x['term'], value=x['value'], category=x['category']) for x in _d['emotions']]\n",
    "        sentence_emotions[_d['sentence']] = _emotions\n",
    "len(sentence_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'fear': 34038, 'sadness': 31586, 'joy': 54212, 'anger': 23406})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter()\n",
    "for k, v in sentence_emotions.items():\n",
    "    count.update([x.category for x in v])\n",
    "training_metadata['labels_distribution'] = dict(count)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping the data for TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3ef1e926ec405abf9ae803a3eae0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=95425), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>copyright law in creating the Project Gutenber...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If she would let him, he would give her everyt...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“It would cease to be a danger if we could def...</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Any words of wisdom now, mama? She thought to ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How at the year’s end all three knights with t...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sadness    joy   fear  \\\n",
       "0  copyright law in creating the Project Gutenber...    0.000  0.000  0.000   \n",
       "1  If she would let him, he would give her everyt...    0.000  0.000  0.000   \n",
       "2  “It would cease to be a danger if we could def...    0.719  0.000  0.802   \n",
       "3  Any words of wisdom now, mama? She thought to ...    0.000  0.312  0.000   \n",
       "4  How at the year’s end all three knights with t...    0.000  0.000  0.000   \n",
       "\n",
       "   anger  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from limbic.limbic_constants import AFFECT_INTENSITY_EMOTIONS as EMOTIONS\n",
    "training_metadata['labels'] = EMOTIONS\n",
    "\n",
    "# The idea is to create a Pandas DataFrame with all the features from this dictionary.\n",
    "sentence_unique_emotions_score = defaultdict(list)\n",
    "for k, v in tqdm(sentence_emotions.items()):\n",
    "    sentence_unique_emotions_score['text'].append(k)\n",
    "    categories = defaultdict(list)\n",
    "    for x in v:\n",
    "        categories[x.category].append(x.value)\n",
    "    emotions_added = []\n",
    "    for c, v_list in categories.items():\n",
    "        sentence_unique_emotions_score[c].append(max(v_list)) \n",
    "        emotions_added.append(c)\n",
    "    for c in EMOTIONS:\n",
    "        if c not in emotions_added:\n",
    "            sentence_unique_emotions_score[c].append(0.0)\n",
    "\n",
    "data = pd.DataFrame.from_dict(sentence_unique_emotions_score)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "training_metadata['train_test_split'] = TRAIN_TEST_SPLIT\n",
    "training_metadata['train_test_split_random_state'] = RANDOM_STATE\n",
    "\n",
    "train, test = train_test_split(data, test_size=TRAIN_TEST_SPLIT, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_EMOTIONS_TRAIN_FILE = '../data/sentence_emotions_train.pickle'\n",
    "SENTENCE_EMOTIONS_TEST_FILE = '../data/sentence_emotions_test.pickle'\n",
    "training_metadata['train_split'] = SENTENCE_EMOTIONS_TRAIN_FILE\n",
    "training_metadata['test_split'] = SENTENCE_EMOTIONS_TEST_FILE\n",
    "\n",
    "train.to_pickle(SENTENCE_EMOTIONS_TRAIN_FILE)  \n",
    "test.to_pickle(SENTENCE_EMOTIONS_TEST_FILE)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "current_date = datetime.now().date().isoformat()\n",
    "metadata_file_path = f'model_metadata_{current_date}.txt'\n",
    "with open(metadata_file_path, 'w') as meta:\n",
    "    meta.write(json.dumps(training_metadata, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
